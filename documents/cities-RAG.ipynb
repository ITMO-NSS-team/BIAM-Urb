{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac752df9-ba88-4384-ad71-393c2bab0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -q langchain sentence-transformers faiss-cpu langchainhub\n",
    "# ! pip install geojson\n",
    "# ! pip install jq\n",
    "# ! pip install chromadb\n",
    "# ! pip install open-clip-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa5f1b71-a1bb-436d-b6ec-2c71bb7e9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import geojson\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from langchain import HuggingFacePipeline, hub\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    pipeline,\n",
    "    AutoModelForCausalLM, \n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7faebdf7-d554-47af-8a44-6f80d65e33b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 11 15:43:48 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                        Off| 00000000:5E:00.0 Off |                    0 |\n",
      "| N/A   68C    P0               32W /  70W|   1335MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab08ded-605b-491b-af28-0d455bc36ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative input with text instead of json\n",
    "\n",
    "buildings_text_path = 'Data/spb_buildings_text2.txt'\n",
    "services_text_path = 'Data/spb_services.txt'\n",
    "\n",
    "with open(buildings_text_path) as file:\n",
    "    lines1 = [line.rstrip() for line in file]\n",
    "\n",
    "with open(services_text_path) as file:\n",
    "    lines2 = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce2627d8-049c-4bb6-82a6-629d4a4cb923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89163\n",
      "Здание по адресу Санкт-Петербург, Джона Рида, 10 корпус 1 в муниципальном округе Правобережный в районе Невский - это Жилой дом. Его управляющая организация называется ООО \"Жилкомсервис № 1 Невского района\". Здание было построено по проекту типа 606-м в 1991.0 году. Площадь здания составляет 1955.8050537109375 квадратных метров, а жилая площадь занимает 15780.900390625 квадратных метров. У здания 10.0 этажей, оно рассчитано на 522.0 человек. Сейчас в здании проживает 667.0 человек. В оснащение здания входит: лифты (всего лифтов 7.0) штук, мусоропровод (всего их 1 штук), центральное отопление (1), холодное водоснабжение (1), горячее водоснабжение (1), электричество (1) и газ (0). В здании проводился ремонт в следующих годах: None. Идентификационный номер здания: 122643, идентификационный номер района: 981, находится ли здание в аварийном состоянии: 0. Координаты здания: [30.452412, 59.921978].\n",
      "14053\n",
      "В здании по адресу None в муниципальном округе Смольнинское в районе Центральный находится организация - Объект культурного наследия, которая называется Торговые ряды В.С.Караваевой (Хлебные амбары Овсянниковых). У данной организации есть веб-сайт None и номер телефона None. Данная организация вмещает в себя 20888.0 человек. Организация работает и открыта для посетителей по следующему графику: None. Идентификационный номер здания: 1060091.0, идентификационный номер района: 1612.0. Координаты здания: [30.386265, 59.931822].\n"
     ]
    }
   ],
   "source": [
    "print(len(lines1))\n",
    "print(lines1[10000])\n",
    "\n",
    "print(len(lines2))\n",
    "print(lines2[10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b77a0-d1c8-483e-9a17-c11da66e2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings for adding data to vector DB\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32150c14-5156-4e3d-8bce-c4c268b38992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data for vector DB\n",
    "\n",
    "def get_splits(lines):\n",
    "    documents = [Document(page_content=text) for text in lines]\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    return splits\n",
    "\n",
    "building_splits = get_splits(lines1)\n",
    "service_splits = get_splits(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfed5762-8dde-4cbb-8788-55bc9ef3669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create to vector DBs for buildings and services\n",
    "\n",
    "db_buildings = '../database/db-buildings'\n",
    "db_services = '../database/db-services'\n",
    "\n",
    "buildings_vectorstore = Chroma.from_documents(\n",
    "    collection_name='db-buildings',\n",
    "    documents=building_splits,\n",
    "    embedding=embedding_function4,\n",
    "    persist_directory=db_buildings\n",
    ")\n",
    "\n",
    "buildings_retriever = buildings_vectorstore.as_retriever()\n",
    "\n",
    "services_vectorstore = Chroma.from_documents(\n",
    "    collection_name='db-services',\n",
    "    documents=service_splits,\n",
    "    embedding=embedding_function4,\n",
    "    persist_directory=db_services\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f984afd3-3414-4151-a961-fc3fa94d7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LLM\n",
    "\n",
    "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
    "DEFAULT_MESSAGE_TEMPLATE = \"<s>{role}\\n{content}</s>\"\n",
    "DEFAULT_RESPONSE_TEMPLATE = \"<s>bot\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и отвечаешь на их вопросы. Используй приведенные ниже фрагменты из контекста, чтобы ответить на вопрос. Если ты не знаешь ответ, просто скажи, что не знаешь. Используй максимум три предложения и будь краток.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035597f0-83cd-466b-be7d-5ab803340c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt for LLM\n",
    "\n",
    "class Conversation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        message_template=DEFAULT_MESSAGE_TEMPLATE,\n",
    "        system_prompt=DEFAULT_SYSTEM_PROMPT,\n",
    "        response_template=DEFAULT_RESPONSE_TEMPLATE\n",
    "    ):\n",
    "        self.message_template = message_template\n",
    "        self.response_template = response_template\n",
    "        self.messages = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        }]\n",
    "\n",
    "    def add_user_message(self, message):\n",
    "        self.messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message\n",
    "        })\n",
    "\n",
    "    def add_bot_message(self, message):\n",
    "        self.messages.append({\n",
    "            \"role\": \"bot\",\n",
    "            \"content\": message\n",
    "        })\n",
    "\n",
    "    def get_prompt(self, tokenizer):\n",
    "        final_text = \"\"\n",
    "        for message in self.messages:\n",
    "            message_text = self.message_template.format(**message)\n",
    "            final_text += message_text\n",
    "        final_text += DEFAULT_RESPONSE_TEMPLATE\n",
    "        return final_text.strip()\n",
    "\n",
    "\n",
    "def generate(model, tokenizer, prompt, generation_config):\n",
    "    data = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    data = {k: v.to(model.device) for k, v in data.items()}\n",
    "    output_ids = model.generate(\n",
    "        **data,\n",
    "        generation_config=generation_config\n",
    "    )[0]\n",
    "    output_ids = output_ids[len(data[\"input_ids\"][0]):]\n",
    "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a75cdd-40f8-4e26-ba59-3a066cbed91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7413bd2-2b88-42af-9243-618cc13e4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "print(generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e033f84-9eaf-42b3-8a2c-17a9adc8c2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea2bfc-6cfb-4b8a-9a11-05e61a66024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "inp = 'Почему трава зелёная?'\n",
    "\n",
    "conversation = Conversation()\n",
    "conversation.add_user_message(inp)\n",
    "prompt = conversation.get_prompt(tokenizer)\n",
    "output = generate(model, tokenizer, prompt, generation_config)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ecd1c-e397-4645-9059-2bcceac678bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61056dcd-7d69-4beb-85b5-4b858bfea6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set question\n",
    "query1 = \"Что находится по адресу 6-я линия В.О., дом 23, литера Б?\"\n",
    "query2 = \"Что находится на 6 линии васильевсвого острова 23?\"\n",
    "query3 = \"Что находится в доме на московском проспекте 78?\"\n",
    "query4 = \"К какому периоду застройки можно отнести дом по адресу Новочеркасский проспект, 41?\"\n",
    "query5 = \"Сколько в здании по адресу Новочеркасский проспект, 41 подъездов?\"\n",
    "query6 = \"Сколько лифтов в здании по адресу Новочеркасский проспект, 41?\"\n",
    "query7 = \"Сколько корпусов у дома с адресом Новочеркасский проспект, 37?\"\n",
    "query8 = \"Что такое корпус у здания?\"\n",
    "query9 = \"Какие архитектурные стили представлены в Санкт-Петербурге?\"\n",
    "query10 = \"Как правильно указать корпус в адресе здания?\"\n",
    "query10 = \"Какие стили были распространены в Санкт-Петербурге в 1973 году?\"\n",
    "\n",
    "query = f\"Вопрос: {query10}\"\n",
    "\n",
    "# Get context\n",
    "def get_context_from_db(vectorstore, query):\n",
    "    docs = vectorstore.similarity_search(query)\n",
    "    docs = [doc.page_content for doc in docs]\n",
    "    docs = '\\n'.join(docs)\n",
    "    return docs\n",
    "    \n",
    "docs_b = get_context_from_db(buildings_vectorstore, query)\n",
    "docs_s = get_context_from_db(services_vectorstore, query)\n",
    "context = f'Контекст: {docs_b}\\n{docs_s}'\n",
    "\n",
    "# Pass context with question to prompt\n",
    "conversation = Conversation()\n",
    "conversation.add_user_message(query)\n",
    "conversation.add_user_message(context)\n",
    "prompt = conversation.get_prompt(tokenizer)\n",
    "\n",
    "# Request result\n",
    "output = generate(model, tokenizer, prompt, generation_config)\n",
    "\n",
    "print(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6acff-1172-4ca6-87e5-41318c0504a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c330e-83b4-4904-9e28-068e690ab9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
